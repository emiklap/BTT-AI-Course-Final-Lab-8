{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Confidence in national government</th>\n",
       "      <th>Democratic Quality</th>\n",
       "      <th>Delivery Quality</th>\n",
       "      <th>Standard deviation of ladder by country-year</th>\n",
       "      <th>Standard deviation/Mean of ladder by country-year</th>\n",
       "      <th>GINI index (World Bank estimate)</th>\n",
       "      <th>GINI index (World Bank estimate), average 2000-15</th>\n",
       "      <th>gini of household income reported in Gallup, by wp5-year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>1.774662</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>1.722688</td>\n",
       "      <td>0.391362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>1.878622</td>\n",
       "      <td>0.394803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>1.785360</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>1.798283</td>\n",
       "      <td>0.475367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.572100</td>\n",
       "      <td>7.503376</td>\n",
       "      <td>0.483552</td>\n",
       "      <td>51.042980</td>\n",
       "      <td>0.577955</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.620585</td>\n",
       "      <td>0.273328</td>\n",
       "      <td>0.482847</td>\n",
       "      <td>-1.879709</td>\n",
       "      <td>-1.403036</td>\n",
       "      <td>1.223690</td>\n",
       "      <td>0.342569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.130896</td>\n",
       "      <td>7.484583</td>\n",
       "      <td>0.525568</td>\n",
       "      <td>51.370525</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.118579</td>\n",
       "      <td>0.871242</td>\n",
       "      <td>0.531691</td>\n",
       "      <td>0.374861</td>\n",
       "      <td>0.409048</td>\n",
       "      <td>-1.773257</td>\n",
       "      <td>-1.312503</td>\n",
       "      <td>1.395396</td>\n",
       "      <td>0.445686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.982855</td>\n",
       "      <td>7.466215</td>\n",
       "      <td>0.528597</td>\n",
       "      <td>51.693527</td>\n",
       "      <td>0.388928</td>\n",
       "      <td>0.094686</td>\n",
       "      <td>0.880638</td>\n",
       "      <td>0.553553</td>\n",
       "      <td>0.339276</td>\n",
       "      <td>0.260557</td>\n",
       "      <td>-1.844364</td>\n",
       "      <td>-1.291594</td>\n",
       "      <td>2.160618</td>\n",
       "      <td>0.542480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.220169</td>\n",
       "      <td>7.461401</td>\n",
       "      <td>0.559072</td>\n",
       "      <td>52.016529</td>\n",
       "      <td>0.522566</td>\n",
       "      <td>0.057072</td>\n",
       "      <td>0.793246</td>\n",
       "      <td>0.564953</td>\n",
       "      <td>0.348332</td>\n",
       "      <td>0.324990</td>\n",
       "      <td>-1.917693</td>\n",
       "      <td>-1.432548</td>\n",
       "      <td>1.796219</td>\n",
       "      <td>0.425627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.661718</td>\n",
       "      <td>7.460144</td>\n",
       "      <td>0.490880</td>\n",
       "      <td>52.339527</td>\n",
       "      <td>0.427011</td>\n",
       "      <td>-0.106340</td>\n",
       "      <td>0.954393</td>\n",
       "      <td>0.496349</td>\n",
       "      <td>0.371326</td>\n",
       "      <td>0.261179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.454051</td>\n",
       "      <td>0.546283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.286599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  Life Ladder  Log GDP per capita  Social support  \\\n",
       "0  Afghanistan  2008     3.723590            7.168690        0.450662   \n",
       "1  Afghanistan  2009     4.401778            7.333790        0.552308   \n",
       "2  Afghanistan  2010     4.758381            7.386629        0.539075   \n",
       "3  Afghanistan  2011     3.831719            7.415019        0.521104   \n",
       "4  Afghanistan  2012     3.782938            7.517126        0.520637   \n",
       "5  Afghanistan  2013     3.572100            7.503376        0.483552   \n",
       "6  Afghanistan  2014     3.130896            7.484583        0.525568   \n",
       "7  Afghanistan  2015     3.982855            7.466215        0.528597   \n",
       "8  Afghanistan  2016     4.220169            7.461401        0.559072   \n",
       "9  Afghanistan  2017     2.661718            7.460144        0.490880   \n",
       "\n",
       "   Healthy life expectancy at birth  Freedom to make life choices  Generosity  \\\n",
       "0                         49.209663                      0.718114    0.181819   \n",
       "1                         49.624432                      0.678896    0.203614   \n",
       "2                         50.008961                      0.600127    0.137630   \n",
       "3                         50.367298                      0.495901    0.175329   \n",
       "4                         50.709263                      0.530935    0.247159   \n",
       "5                         51.042980                      0.577955    0.074735   \n",
       "6                         51.370525                      0.508514    0.118579   \n",
       "7                         51.693527                      0.388928    0.094686   \n",
       "8                         52.016529                      0.522566    0.057072   \n",
       "9                         52.339527                      0.427011   -0.106340   \n",
       "\n",
       "   Perceptions of corruption  Positive affect  Negative affect  \\\n",
       "0                   0.881686         0.517637         0.258195   \n",
       "1                   0.850035         0.583926         0.237092   \n",
       "2                   0.706766         0.618265         0.275324   \n",
       "3                   0.731109         0.611387         0.267175   \n",
       "4                   0.775620         0.710385         0.267919   \n",
       "5                   0.823204         0.620585         0.273328   \n",
       "6                   0.871242         0.531691         0.374861   \n",
       "7                   0.880638         0.553553         0.339276   \n",
       "8                   0.793246         0.564953         0.348332   \n",
       "9                   0.954393         0.496349         0.371326   \n",
       "\n",
       "   Confidence in national government  Democratic Quality  Delivery Quality  \\\n",
       "0                           0.612072           -1.929690         -1.655084   \n",
       "1                           0.611545           -2.044093         -1.635025   \n",
       "2                           0.299357           -1.991810         -1.617176   \n",
       "3                           0.307386           -1.919018         -1.616221   \n",
       "4                           0.435440           -1.842996         -1.404078   \n",
       "5                           0.482847           -1.879709         -1.403036   \n",
       "6                           0.409048           -1.773257         -1.312503   \n",
       "7                           0.260557           -1.844364         -1.291594   \n",
       "8                           0.324990           -1.917693         -1.432548   \n",
       "9                           0.261179                 NaN               NaN   \n",
       "\n",
       "   Standard deviation of ladder by country-year  \\\n",
       "0                                      1.774662   \n",
       "1                                      1.722688   \n",
       "2                                      1.878622   \n",
       "3                                      1.785360   \n",
       "4                                      1.798283   \n",
       "5                                      1.223690   \n",
       "6                                      1.395396   \n",
       "7                                      2.160618   \n",
       "8                                      1.796219   \n",
       "9                                      1.454051   \n",
       "\n",
       "   Standard deviation/Mean of ladder by country-year  \\\n",
       "0                                           0.476600   \n",
       "1                                           0.391362   \n",
       "2                                           0.394803   \n",
       "3                                           0.465942   \n",
       "4                                           0.475367   \n",
       "5                                           0.342569   \n",
       "6                                           0.445686   \n",
       "7                                           0.542480   \n",
       "8                                           0.425627   \n",
       "9                                           0.546283   \n",
       "\n",
       "   GINI index (World Bank estimate)  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "5                               NaN   \n",
       "6                               NaN   \n",
       "7                               NaN   \n",
       "8                               NaN   \n",
       "9                               NaN   \n",
       "\n",
       "   GINI index (World Bank estimate), average 2000-15  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "   gini of household income reported in Gallup, by wp5-year  \n",
       "0                                                NaN         \n",
       "1                                           0.441906         \n",
       "2                                           0.327318         \n",
       "3                                           0.336764         \n",
       "4                                           0.344540         \n",
       "5                                           0.304368         \n",
       "6                                           0.413974         \n",
       "7                                           0.596918         \n",
       "8                                           0.418629         \n",
       "9                                           0.286599         "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(WHRDataSet_filename)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. World Happiness Report 2018 Dataset\n",
    "\n",
    "2. We will be predicting the happiness of various countries based on 'Social Support', 'Healthy life expectancy at birth', 'Freedom to make life choices', and 'generosity'. The label is the 'Life Ladder' column.\n",
    "\n",
    "3. This is a supervised learning problem and a regression problem. The goal of our model is to be able to provide a Life Ladder score for a given country.\n",
    "\n",
    "4. The features we will be using are 'Country', 'Year', 'Social Support', 'Healthy life expectancy at birth', 'Freedom to make life choices', and 'generosity'.\n",
    "\n",
    "5. Happiness is not equal around the world, so our goal with this model is to better understand what factors make certain countries happier than others. With this information we would like to help make the world a happier place on a global scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1562.000000\n",
      "mean        5.433676\n",
      "std         1.121017\n",
      "min         2.661718\n",
      "25%         4.606351\n",
      "50%         5.332600\n",
      "75%         6.271025\n",
      "max         8.018934\n",
      "Name: Life Ladder, dtype: float64\n",
      "-------------------------------------------\n",
      "Col \"country\" has 0 null values.\n",
      "count           1562\n",
      "unique           164\n",
      "top       Kyrgyzstan\n",
      "freq              12\n",
      "Name: country, dtype: object\n",
      "---------------------------------------------------------------------\n",
      "Col \"year\" has 0 null values.\n",
      "count    1562.000000\n",
      "mean     2011.820743\n",
      "std         3.419787\n",
      "min      2005.000000\n",
      "25%      2009.000000\n",
      "50%      2012.000000\n",
      "75%      2015.000000\n",
      "max      2017.000000\n",
      "Name: year, dtype: float64\n",
      "---------------------------------------------------------------------\n",
      "Col \"Social support\" has 13 null values.\n",
      "count    1549.000000\n",
      "mean        0.810669\n",
      "std         0.119370\n",
      "min         0.290184\n",
      "25%         0.748304\n",
      "50%         0.833047\n",
      "75%         0.904329\n",
      "max         0.987343\n",
      "Name: Social support, dtype: float64\n",
      "---------------------------------------------------------------------\n",
      "Col \"Healthy life expectancy at birth\" has 9 null values.\n",
      "count    1553.000000\n",
      "mean       62.249887\n",
      "std         7.960671\n",
      "min        37.766476\n",
      "25%        57.299580\n",
      "50%        63.803192\n",
      "75%        68.098228\n",
      "max        76.536362\n",
      "Name: Healthy life expectancy at birth, dtype: float64\n",
      "---------------------------------------------------------------------\n",
      "Col \"Freedom to make life choices\" has 29 null values.\n",
      "count    1533.000000\n",
      "mean        0.728975\n",
      "std         0.145408\n",
      "min         0.257534\n",
      "25%         0.633754\n",
      "50%         0.748014\n",
      "75%         0.843628\n",
      "max         0.985178\n",
      "Name: Freedom to make life choices, dtype: float64\n",
      "---------------------------------------------------------------------\n",
      "Col \"Generosity\" has 80 null values.\n",
      "count    1482.000000\n",
      "mean        0.000079\n",
      "std         0.164202\n",
      "min        -0.322952\n",
      "25%        -0.114313\n",
      "50%        -0.022638\n",
      "75%         0.094649\n",
      "max         0.677773\n",
      "Name: Generosity, dtype: float64\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "features = ['country', 'year', 'Social support', 'Healthy life expectancy at birth', 'Freedom to make life choices', 'Generosity']\n",
    "\n",
    "print(df['Life Ladder'].describe())\n",
    "print('-------------------------------------------')\n",
    "\n",
    "#Printing details on the features I want to use\n",
    "for i in features:\n",
    "    print('Col \"' + i + '\" has ' + str(df[i].isnull().sum()) + ' null values.')\n",
    "    print(df[i].describe())\n",
    "    print('---------------------------------------------------------------------')\n",
    "\n",
    "#We need to clean up missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "y = df['Life Ladder']\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                             0\n",
       "year                                0\n",
       "Social support                      0\n",
       "Healthy life expectancy at birth    0\n",
       "Freedom to make life choices        0\n",
       "Generosity                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X.isnull(), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data?Â \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  After looking more carefully at my features, I decided that we do not need 'country' and 'year'. Instead, we will look soley at the socioeconomic factors across all countries to see how they impact happiness. To make sure the rest of the features are truly relevant to the project, I will create a correlation matrix to see how each correlates to the label ('Life Ladder').\n",
    "\n",
    "-  My plan is to test various regression models to find the one with the best performance. Then, using this model, I want to build an interface that allows the user to create new predicitions on the happiness score produced by specified feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['country', 'year'])\n",
    "features = ['Social support', 'Healthy life expectancy at birth', 'Freedom to make life choices', 'Generosity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Life Ladder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Social support</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.52370</td>\n",
       "      <td>0.46006</td>\n",
       "      <td>0.24398</td>\n",
       "      <td>0.65633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthy life expectancy at birth</th>\n",
       "      <td>0.52370</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.33172</td>\n",
       "      <td>0.16047</td>\n",
       "      <td>0.66757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <td>0.46006</td>\n",
       "      <td>0.33172</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.46765</td>\n",
       "      <td>0.61530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generosity</th>\n",
       "      <td>0.24398</td>\n",
       "      <td>0.16047</td>\n",
       "      <td>0.46765</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.39207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Life Ladder</th>\n",
       "      <td>0.65633</td>\n",
       "      <td>0.66757</td>\n",
       "      <td>0.61530</td>\n",
       "      <td>0.39207</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Social support  \\\n",
       "Social support                           1.00000   \n",
       "Healthy life expectancy at birth         0.52370   \n",
       "Freedom to make life choices             0.46006   \n",
       "Generosity                               0.24398   \n",
       "Life Ladder                              0.65633   \n",
       "\n",
       "                                  Healthy life expectancy at birth  \\\n",
       "Social support                                             0.52370   \n",
       "Healthy life expectancy at birth                           1.00000   \n",
       "Freedom to make life choices                               0.33172   \n",
       "Generosity                                                 0.16047   \n",
       "Life Ladder                                                0.66757   \n",
       "\n",
       "                                  Freedom to make life choices  Generosity  \\\n",
       "Social support                                         0.46006     0.24398   \n",
       "Healthy life expectancy at birth                       0.33172     0.16047   \n",
       "Freedom to make life choices                           1.00000     0.46765   \n",
       "Generosity                                             0.46765     1.00000   \n",
       "Life Ladder                                            0.61530     0.39207   \n",
       "\n",
       "                                  Life Ladder  \n",
       "Social support                        0.65633  \n",
       "Healthy life expectancy at birth      0.66757  \n",
       "Freedom to make life choices          0.61530  \n",
       "Generosity                            0.39207  \n",
       "Life Ladder                           1.00000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['Social support', 'Healthy life expectancy at birth', 'Freedom to make life choices', 'Generosity', 'Life Ladder']\n",
    "corr_matrix = round(df[test].corr(),5)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we can see that the features have notable correlation to the 'Life Ladder' label.\n",
    "'Generosity' has the least correlation, but I still want to include it in my model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST LINEAR REGRESSION\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_lr_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.6455451699799956\n",
      "[LR] R2: 0.5784710758644042\n"
     ]
    }
   ],
   "source": [
    "#compute the RMSE\n",
    "lr_rmse = mean_squared_error(y_test, y_lr_pred, squared=False)\n",
    "\n",
    "#compute the R2 score\n",
    "lr_r2 = r2_score(y_test, y_lr_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(lr_rmse))\n",
    "print('[LR] R2: {0}'.format(lr_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "#TEST DECISION TREE\n",
    "md = [2, 4, 8, 12]\n",
    "msl = [4, 8, 12, 25, 50, 75]\n",
    "param_grid={'max_depth':md, 'min_samples_leaf':msl}\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "dt_grid = GridSearchCV(dt_regressor, param_grid, cv=3,scoring='neg_root_mean_squared_error', verbose=1)\n",
    "dt_grid_search = dt_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] RMSE for the best model is : 0.61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'min_samples_leaf': 12}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_DT = -1 * dt_grid_search.best_score_\n",
    "print(\"[DT] RMSE for the best model is : {:.2f}\".format(rmse_DT))\n",
    "\n",
    "dt_best_params = dt_grid_search.best_params_\n",
    "dt_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] Root Mean Squared Error: 0.6631638584376104\n",
      "[DT] R2: 0.5551477337511316\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeRegressor(max_depth = dt_best_params['max_depth'], min_samples_leaf =dt_best_params['min_samples_leaf'])\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_dt_pred = dt_model.predict(X_test)\n",
    "dt_rmse = mean_squared_error(y_test, y_dt_pred, squared=False)\n",
    "                             \n",
    "dt_r2 = r2_score(y_test, y_dt_pred)\n",
    "print('[DT] Root Mean Squared Error: {0}'.format(dt_rmse))\n",
    "print('[DT] R2: {0}'.format(dt_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST STACKING\n",
    "estimators = [(\"DT\", DecisionTreeRegressor(max_depth=8, min_samples_leaf=12)), (\"LR\", LinearRegression())]\n",
    "stacking_model = StackingRegressor(estimators=estimators, passthrough=False)\n",
    "stacking_model.fit(X_train, y_train)\n",
    "stacking_pred = stacking_model.predict(X_test)\n",
    "stack_rmse = np.sqrt(mean_squared_error(y_test, stacking_pred))\n",
    "stack_r2 = r2_score(y_test, stacking_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "[GBDT] RMSE for the best model is : 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST GRADIENT BOOSTED DECISION TREES\n",
    "md = [2, 4, 8, 12]\n",
    "n_est = [100, 150, 200, 250, 300, 350, 400]\n",
    "param_grid={'max_depth':md, 'n_estimators':n_est}\n",
    "\n",
    "gbdt_model = GradientBoostingRegressor()\n",
    "gbdt_grid = GridSearchCV(gbdt_model, param_grid, cv=3,scoring='neg_root_mean_squared_error', verbose=1)\n",
    "gbdt_grid_search = gbdt_grid.fit(X_train, y_train)\n",
    "\n",
    "rmse_gbdt = -1 * dt_grid_search.best_score_\n",
    "print(\"[GBDT] RMSE for the best model is : {:.2f}\".format(rmse_gbdt))\n",
    "\n",
    "gbdt_best_params = gbdt_grid_search.best_params_\n",
    "gbdt_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GBDT] Root Mean Squared Error: 0.6085252245677819\n",
      "[GBDT] R2: 0.6254314769306129\n"
     ]
    }
   ],
   "source": [
    "gbdt_model = GradientBoostingRegressor(max_depth = gbdt_best_params['max_depth'], n_estimators = gbdt_best_params['n_estimators'])\n",
    "gbdt_model.fit(X_train, y_train)\n",
    "\n",
    "y_GBDT_pred = gbdt_model.predict(X_test)\n",
    "gbdt_rmse = mean_squared_error(y_test, y_GBDT_pred, squared=False)\n",
    "gbdt_r2 = r2_score(y_test, y_GBDT_pred)\n",
    "print('[GBDT] Root Mean Squared Error: {0}'.format(gbdt_rmse))\n",
    "print('[GBDT] R2: {0}'.format(gbdt_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 126 out of 126 | elapsed:   59.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] RMSE for the best model is : 0.51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'n_estimators': 200}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST RANDOM FOREST\n",
    "\n",
    "md = [4, 8, 12, 16, 32, 64]\n",
    "n_est = [100, 150, 200, 250, 300, 350, 400]\n",
    "param_grid={'max_depth':md, 'n_estimators':n_est}\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_grid = GridSearchCV(rf_model, param_grid, cv=3,scoring='neg_root_mean_squared_error', verbose=1)\n",
    "rf_grid_search = rf_grid.fit(X_train, y_train)\n",
    "\n",
    "rmse_rf = -1 * rf_grid_search.best_score_\n",
    "print(\"[RF] RMSE for the best model is : {:.2f}\".format(rmse_rf))\n",
    "\n",
    "rf_best_params = rf_grid_search.best_params_\n",
    "rf_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] Root Mean Squared Error: 0.6693475008686296\n",
      "[RF] R2: 0.5468130448037923\n"
     ]
    }
   ],
   "source": [
    "rf_model = GradientBoostingRegressor(max_depth = rf_best_params['max_depth'], n_estimators = rf_best_params['n_estimators'])\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "rf_rmse = mean_squared_error(y_test, y_rf_pred, squared=False)\n",
    "rf_r2 = r2_score(y_test, y_rf_pred)\n",
    "print('[RF] Root Mean Squared Error: {0}'.format(rf_rmse))\n",
    "print('[RF] R2: {0}'.format(rf_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLOT ALL THE ALGORITHMS' RESULTS\n",
    "RMSE_Results = [stack_rmse, lr_rmse, dt_rmse, gbdt_rmse, rf_rmse]\n",
    "R2_Results = [stack_r2, lr_r2, dt_r2, gbdt_r2, rf_r2]\n",
    "rg= np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(rg, RMSE_Results, width, label=\"RMSE\")\n",
    "\n",
    "plt.bar(rg+width, R2_Results, width, label='R2')\n",
    "labels = ['Stacking','LR', 'DT', 'GBDT', 'RF']\n",
    "plt.xticks(rg + width/2, labels)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE/R2\")\n",
    "plt.ylim([0,1])\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is very similiar for all models, but GBDT might be the best to use, as the Pearson correlation coefficient (R^2 value) is highest and the root means squared error (RMSE) is lowest. This means that for this model there is the highest correlation between the test and training data while there is also the lowest difference between the test values and training values.\n",
    "\n",
    "Another valid model with similiar performance is the stacking model. \n",
    "\n",
    "<br>\n",
    "For now, I'll stick to using the GBDT model. The final step of this project will be to create an interactive interface/tool that will allow users to output a predicted \"happiness\" score based on values they input. (Inspired by the interactive learning tools we used in week 7.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each of the following features, enter: min, 25%, 50%, 75%, max\n",
      "How much 'Social support' does this hypothetical country have? max\n",
      "How much 'Healthy life expectancy at birth' does this hypothetical country have? max\n",
      "How much 'Freedom to make life choices' does this hypothetical country have? min\n",
      "How much 'Generosity' does this hypothetical country have? min\n"
     ]
    }
   ],
   "source": [
    "#PREDICTING NEW VALUES\n",
    "print(\"For each of the following features, enter: min, 25%, 50%, 75%, max\")\n",
    "valid_answers = ['min', '25%', '50%', '75%', 'max']\n",
    "new_vals_std = []\n",
    "new_data = [0, 0, 0, 0]\n",
    "\n",
    "'''\n",
    "The user will decide if their hypotetical country has min, max or some in between value \n",
    "for the 4 features we are considering.\n",
    "\n",
    "Note to the grader: not sure if y'all run each ipynb individually, but if you can pls run this \n",
    "cell and the one below to test different values!\n",
    "'''\n",
    "for i in features:\n",
    "    user_input = input(f\"How much '{i}' does this hypothetical country have? \")\n",
    "    while user_input not in valid_answers:\n",
    "        user_input = input(f\"How much '{i}' does this hypothetical country have? \")\n",
    "    new_vals_std.append(user_input)\n",
    "\n",
    "for i in range(0, 4):\n",
    "    new_data[i] = X[features[i]].describe()[new_vals_std[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your country will have a happiness value of [5.79009125].\n",
      "-----------------------------------------------------------\n",
      "For reference, here are some global stats on happiness values from the data set:\n",
      "(Compare your number with these to see how 'happy' your country is)\n",
      "count    382.000000\n",
      "mean       5.816413\n",
      "std        1.033160\n",
      "min        2.936221\n",
      "25%        5.062853\n",
      "50%        5.832245\n",
      "75%        6.638913\n",
      "max        7.788232\n",
      "Name: Life Ladder, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_data_df = pd.DataFrame([new_data], columns=features)\n",
    "\n",
    "new_prediction = gbdt_model.predict(new_data_df)\n",
    "print(f\"Your country will have a happiness value of {new_prediction}.\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"For reference, here are some global stats on happiness values from the data set:\")\n",
    "print(\"(Compare your number with these to see how 'happy' your country is)\")\n",
    "print(df['Life Ladder'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
